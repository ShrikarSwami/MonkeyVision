# ðŸ’ MonkeyVision

Real-time hand + face gesture fun in Python/OpenCV + MediaPipe.  
Point ðŸ‘‰ to cue the â€œsayâ€ monkey, touch index to mouth ðŸ¤« to show the â€œthinkâ€ monkey â€” with sound!

Repo: https://github.com/ShrikarSwami/MonkeyVision  
Demo video: https://youtu.be/Cj1oETl1BUY

---

## ðŸŽ¬ Demo

- POINT ðŸ‘‰ = â€œsayâ€ monkey
- THINK ðŸ¤« (index fingertip near mouth) = â€œthinkâ€ monkey

If youâ€™re reading this on GitHub, youâ€™ll also see GIFs in `docs/` when added.  
Demo video again (because hype): https://youtu.be/Cj1oETl1BUY

---

## âœ¨ Features

- ðŸ–ï¸ One-hand gesture detection  
  - **POINT**: index up (others down)  
  - **THINK**: index fingertip near mouth (6% of frame diagonal)
- ðŸ™‚ Face mesh â†’ mouth center + smart head box
- ðŸ§© Alpha-blended PNG monkeys overlayed on your webcam feed
- ðŸ”Š One-shot music trigger the **first** time you hit POINT
- ðŸ–¥ï¸ Cross-platform camera backend selection (macOS, Windows, Linux)
- âš¡ HUD with FPS + current gesture label

> âœ… All image/audio assets (`monkey_*.png`, `music.mp3`) are included in the repo.  
> The script looks for them right next to `webcam.py` â€” nothing extra to download.

---

## ðŸ§° Requirements

- **Python 3.11** (MediaPipe wheels arenâ€™t out yet for 3.13 at time of writing)
- macOS / Windows / Linux with a webcam
- Internet only for `pip install` (no cloud at runtime)

---

## ðŸš€ TL;DR â€” Quick Start

1) **Download / Clone**

- Easiest: click the green **Code** button â†’ **Download ZIP** (default branch is cross-platform).  
  Unzip, then `cd` into the project folder.

- Or clone:
  ```bash
  git clone https://github.com/ShrikarSwami/MonkeyVision.git
  cd MonkeyVision
