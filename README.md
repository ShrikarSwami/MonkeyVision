# ğŸ’ MonkeyVision

Real-time hand + face gesture fun in Python/OpenCV + MediaPipe.  
Point ğŸ‘‰ to cue the â€œsayâ€ monkey, touch index to mouth ğŸ¤« to show the â€œthinkâ€ monkey â€” with sound!

https://github.com/ShrikarSwami/MonkeyVision

---

## Demo

![POINT demo](docs/point.gif)
![THINK demo](docs/think.gif)

> Tip: Drop short MP4s in `docs/` and embed as GIFs (GitHub renders GIFs best).  
> You can also add a YouTube link or GitHub asset for your dorm demo video.

---

## Features
- ğŸ–ï¸ One-hand gesture detection (index up = POINT, index to mouth = THINK)
- ğŸ™‚ Face mesh for mouth + head box
- ğŸ§© Alpha-blended PNG monkeys overlayed on your video
- ğŸ”Š One-shot music trigger the first time you hit POINT
- ğŸ–¥ï¸ Cross-platform camera backend (macOS, Windows, Linux)
- âš¡ HUD with FPS + current gesture

---

## Requirements

- **Python 3.11** (MediaPipe doesnâ€™t provide wheels for 3.13 yet)
- macOS/Windows/Linux with a webcam

Install from the repo root:

```bash
# macOS
python3.11 -m venv .venv311
source .venv311/bin/activate
pip install -r requirements.txt

# Windows (PowerShell)
py -3.11 -m venv .venv311
.\.venv311\Scripts\Activate.ps1
pip install -r requirements.txt
